{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:469: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:470: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:471: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:472: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:473: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:476: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import preprocessing\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "from keras.constraints import max_norm\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample= 125\n",
    "Nfeatures= 513"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(inCSV1, inCSV0):\n",
    "    print(inCSV1)\n",
    "    df1= pd.read_csv(inCSV1)\n",
    "    print(df1.shape)\n",
    "    N_sample= df1.shape[0]\n",
    "    print(N_sample)\n",
    "    print(inCSV0)\n",
    "    \n",
    "    df= pd.read_csv(inCSV0)\n",
    "    print(df.shape)\n",
    "    \n",
    "    #df= df.sample(N_sample)# under sample\n",
    "    \n",
    "    df= df.append(df1, ignore_index=True)\n",
    "    print(df.shape)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/E/download/full/train1.csv\n",
      "(5780, 64126)\n",
      "5780\n",
      "/Volumes/E/download/full/train0.csv\n",
      "(12254, 64126)\n",
      "(18034, 64126)\n"
     ]
    }
   ],
   "source": [
    "inTrain1= '/Volumes/E/download/full/train1.csv'\n",
    "inTrain0= '/Volumes/E/download/full/train0.csv'\n",
    "dfTrain= readCSV(inTrain1, inTrain0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/E/download/full/test1.csv\n",
      "(1952, 64126)\n",
      "1952\n",
      "/Volumes/E/download/full/test0.csv\n",
      "(4846, 64126)\n",
      "(6798, 64126)\n"
     ]
    }
   ],
   "source": [
    "inTest1= '/Volumes/E/download/full/test1.csv'\n",
    "inTest0= '/Volumes/E/download/full/test0.csv'\n",
    "dfTest= readCSV(inTest1, inTest0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readDF(df, NSamples):\n",
    "    df= df.sample(NSamples)\n",
    "    y= df[\"PHQ_Binary\"].to_numpy()\n",
    "    df_Nolabel= df.drop(['PHQ_Binary'], axis=1)\n",
    "    X= df_Nolabel.to_numpy().reshape( NSamples, sample, Nfeatures, 1)\n",
    "    print(X.shape)\n",
    "    return X, y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSamplesTrain= 18000\n",
    "NSamplesTest= 6700\n",
    "# NSamplesTrain= 200\n",
    "# NSamplesTest= 100\n",
    "X_train, y_train= readDF(dfTrain, NSamplesTrain)\n",
    "X_test, y_test= readDF(dfTest, NSamplesTest) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn(X_train, y_train, X_test, y_test, batch_size, epochs, input_shape):\n",
    "    nb_classes= 2\n",
    "    L_weight= 0.01\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add( Conv2D(32, (3, 3), padding='valid', strides=1, \n",
    "                     kernel_constraint=max_norm(3), bias_constraint=max_norm(3),\n",
    "                     bias_regularizer=l2(L_weight),\n",
    "                     input_shape=input_shape, activation='relu'))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(MaxPooling2D(pool_size=(1, 3), strides=(1, 3)))\n",
    "    \n",
    "    model.add( Conv2D(32, (3, 3), padding='valid', strides=1, \n",
    "                     kernel_constraint=max_norm(3), bias_constraint=max_norm(3),\n",
    "                     bias_regularizer=l2(L_weight),\n",
    "                     input_shape=input_shape, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(MaxPooling2D(pool_size=(1, 3), strides=(1, 3)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.6)) \n",
    "\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.6))\n",
    "\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer='adadelta',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(y_train),\n",
    "                                                 y_train)\n",
    "    \n",
    "    history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "                        class_weight=class_weights,\n",
    "                        verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 3\n",
    "print(batch_size, epochs)\n",
    "\n",
    "input_shape= (sample, Nfeatures, 1)\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, history= cnn(X_train, y_train, X_test, y_test, batch_size, epochs, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_curve(h):\n",
    "    acc, loss, val_acc, val_loss = h.history['acc'], h.history['loss'], h.history['val_acc'], h.history['val_loss']\n",
    "    epoch = len(acc)\n",
    "    plt.figure(figsize=(17, 5))\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.plot(range(epoch), loss, label='Train')\n",
    "    plt.plot(range(epoch), val_loss, label='val')\n",
    "    plt.title('Loss over ' + str(epoch) + ' Epochs', size=15)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    plt.plot(range(epoch), acc, label='Train')\n",
    "    plt.plot(range(epoch), val_acc, label='val')\n",
    "    plt.title('Accuracy over ' + str(epoch) + ' Epochs', size=15)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "accuracy_curve(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_auc(y_test, y_score):\n",
    "    \n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    thresholds = dict()\n",
    "\n",
    "    for i in range(2):\n",
    "        fpr[i], tpr[i], thresholds[i] = roc_curve(y_test[:, i], y_score[:, i])\n",
    "        #print(thresholds)\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr[1], tpr[1], color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[1])\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "    return\n",
    "\n",
    "def modelMetrics(y_test, y_score):\n",
    "    y_prob= [ y[1] for y in y_score]\n",
    "    #print(y_prob)\n",
    "    sns.distplot(y_prob);\n",
    "    y_prob_mean= np.mean(y_prob)\n",
    "    print(\"mean: \", y_prob_mean)\n",
    "    \n",
    "    y_pred= [ int(y > y_prob_mean) for y in y_prob]\n",
    "    accuracy= accuracy_score(y_test, y_pred)\n",
    "    precision, recall, fscore, _= precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
    "\n",
    "    print(\"accuracy: %.2f%%\" % (accuracy*100))\n",
    "    print(\"precision: %.2f%%\" % (precision*100))\n",
    "    print(\"recall: %.2f%%\" % (recall*100))\n",
    "    print(\"fscore: %.2f%%\" % (fscore*100))\n",
    "    print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "def valuationMetrics(model, X_test, y_test):\n",
    "    y_prob = model.predict(X_test, batch_size=32, verbose=1)\n",
    "    y_test_ = np.eye(2)[y_test]\n",
    "    plot_auc(y_test_, y_prob)\n",
    "    modelMetrics(y_test, y_prob)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valuationMetrics(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= '../../media/model/depression.h5'\n",
    "model.save(path)\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load = load_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
